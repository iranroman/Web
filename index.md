<p align="txt-align: center;">
  <img src="media/waves.jpg" style="max-width: 100%; height: auto;" />
</p>
<center> <h1>Iran R. Roman</h1> </center>

---

I'm a postdoctoral scholar at New York University's Music and Audio Research Laboratory, where I carry out research in theoretical neuroscience and machine listening. 

My goal is to develop machines that can listen to music and speech like humans do. So far, I have built mathematical models that explain how the human brain anticipates and synchronizes with the rhythms present in music and speech. 

I hold a Ph.D. from Stanford University in computer-based music theory and acoustics. My advisors were Julius Smith, Chris Chafe, and Edward Large. 

Previous to my Ph.D. studies I majored in biology, music theory, and German language at the University of North Texas.

In parallel to my academic career, I have carried out machine listening research at Apple, Tesla, and Plantronics. 

---

## contact me

email: iran [at] ccrma.stanford.edu
<pre>
<a href=
https://www.github.com/iranroman
style="font-size: 17px;" >github</a>   <a href=
https://www.linkedin.com/in/iran-roman
style="font-size: 17px;" >linkedin</a>   <a href=
https://scholar.google.com/citations?user=W_PoFfkAAAAJ&hl=en&oi=ao
style="font-size: 17px;" >scholar</a>   
</pre>
